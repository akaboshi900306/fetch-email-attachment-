{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client   # library for Microsoft Outlook access\n",
    "import os  \n",
    "import datetime\n",
    "import pyodbc    # library for SQL Server access\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import time\n",
    "import uuid\n",
    "import os\n",
    "import os.path\n",
    "from subprocess import Popen\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "keywords = pd.DataFrame(columns=['PARM','ORIGIN','PARMVALUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(16, 20, 47, 461167)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(datetime.datetime.today() + datetime.timedelta(days=1)).time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE: Allentown Transfer request\n",
      "Tableau DOR Report\n",
      "[EXTERNAL] A Basic NLP Tutorial for News Multiclass Categorization | Armand Olivares\n",
      "FW: CENTRALIZED DC TRANSFERS - FW 24\n",
      "FW: CENTRALIZED DC TRANSFERS - FW 24\n",
      "FW: Allentown Transfer request\n",
      "State Quarantine Requirements After Personal Travel\n",
      "RE: Allentown Transfer request\n",
      "RE: Allentown Transfer request\n",
      "Gary 1:1\n",
      "FW: CENTRALIZED DC TRANSFERS - FW 24\n",
      "Caring Conversations Series: Engaging Mid-Level Leaders to Advance the Discussion of Racial Justice \n",
      "[EXTERNAL] Invitation to Web seminar: IPR All Hands Q1\n",
      "RE: Pipeline OOS View\n",
      "FW: CENTRALIZED DC TRANSFERS - FW 24\n",
      "FW: CENTRALIZED DC TRANSFERS - FW 24\n",
      "FW: CENTRALIZED DC TRANSFERS - FW 24\n",
      "[EXTERNAL] The Alternative to Web Scraping | Doug Guthrie in Towards Data Science\n",
      "[EXTERNAL] Celine (Hsiang-Hsin) Wang's invitation is waiting for your response\n",
      "MyAnalytics | Collaboration Edition\n",
      "[EXTERNAL] 536 AD — the worst year in history | Saamir Ansari in Lessons from History\n",
      "End User Digest: 2 New Messages \n",
      "On taking care...\n",
      "End User Digest: 3 New Messages \n",
      "Records Management At Home \n",
      "RE: ACTION REQUIRED:  Velocity codes not in sync - db2 prthd.STRSK_OH\n",
      "Unconscious Bias Annual Training\n",
      "Re: ACTION REQUIRED:  Velocity codes not in sync - db2 prthd.STRSK_OH\n",
      "Re: ACTION REQUIRED:  Velocity codes not in sync - db2 prthd.STRSK_OH\n",
      "IPR Newsletter FW 24 \n",
      "Summer of Development - Week 5 Update\n",
      "Career Community Newsletter is Back with a July Edition\n",
      "Records Management At Home \n",
      "Supply Chain June Associates of the Month\n",
      "AHM Survey\n",
      "RE: ACTION REQUIRED:  Velocity codes not in sync - db2 prthd.STRSK_OH\n",
      "[EXTERNAL] Features You Likely Don’t Use in Python 3 — But You Should | Amritansh Sagar in Towards Data Science\n",
      "Re: ACTION REQUIRED:  Velocity codes not in sync - db2 prthd.STRSK_OH\n",
      "RE: ACTION REQUIRED:  Velocity codes not in sync - db2 prthd.STRSK_OH\n",
      "Re: ACTION REQUIRED:  Velocity codes not in sync - db2 prthd.STRSK_OH\n",
      "Gary 1:1\n",
      "[EXTERNAL] SDSC20 Update\n",
      "[EXTERNAL] The Home Depot Tableau Thursday 7.23\n",
      "[EXTERNAL] Registration approved for Web seminar: Getting the most from Tableau Server\n",
      "[EXTERNAL] Free Online Classes - Live and Streaming Any Time\n",
      "Doings at the SSC - Week of July 13 \n",
      "End User Digest: 1 New Message \n"
     ]
    }
   ],
   "source": [
    "import win32com.client\n",
    "\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "\n",
    "inbox = outlook.GetDefaultFolder(6) # \"6\" refers to the index of a folder - in this case,\n",
    "                                    # the inbox. You can change that number to reference\n",
    "                                    # any other folder\n",
    "messages = inbox.Items.restrict(\"[ReceivedTime]> '7/10/2020 08:00 AM'\")\n",
    "#messages = inbox.Items.restrict(\"[ReceivedTime]\"> datetime.datetime.today())\n",
    "for message in messages:\n",
    "    print (message.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in messages:  #\n",
    "    if re.search('^FW.*Results$', message.subject) is not None: # if the subject fits \n",
    "        # Get PARM\n",
    "        a = message\n",
    "        body = message.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THD Q1 2020 Earnings Release.pdf\n"
     ]
    }
   ],
   "source": [
    "attachment = a.Attachments\n",
    "count = a.Attachments.Count\n",
    "if count > 0:\n",
    "    attachment = attachment.Item(1)\n",
    "    print (attachment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment.SaveAsFile('C:\\\\Users\\\\yxg0rzh\\\\OneDrive - The Home Depot\\\\Desktop\\\\New folder (2)' + '\\\\'+ str(attachment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'C:\\\\Users\\\\yxg0rzh\\\\OneDrive - The Home Depot\\\\Desktop\\\\New folder (2)' + '\\\\'+ str(attachment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "today = dt.datetime.today().strftime('%Y%m%d')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_xls = pd.read_excel(name, index_col=None)\n",
    "data_xls.to_csv(\"C:\\\\Users\\\\yxg0rzh\\\\OneDrive - The Home Depot\\\\Desktop\\\\New folder (2)\\\\Thursday_upload\\\\upload_{}.csv\".format(today) , index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The rain in Spain']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile(\"^The.*Spain$\")\n",
    "list(filter(regex.search,txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 86 rows into yxg0rzh:my_table.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "filename = \"C:\\\\Users\\\\yxg0rzh\\\\OneDrive - The Home Depot\\\\Desktop\\\\New folder (2)\\\\Thursday_upload\\\\upload_{}.csv\".format(today)\n",
    "dataset_id = 'yxg0rzh'\n",
    "table_id = 'my_table'\n",
    "\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print(\"Loaded {} rows into {}:{}.\".format(job.output_rows, dataset_id, table_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
